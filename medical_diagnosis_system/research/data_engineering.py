"""
æ•°æ®å·¥ç¨‹æ¨¡å— - æ•°æ®æ¸…æ´—ã€ç‰¹å¾å·¥ç¨‹ã€æ¢ç´¢æ€§æ•°æ®åˆ†æ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
import warnings
warnings.filterwarnings('ignore')

class DataProcessor:
    """æ•°æ®å¤„ç†å’Œç‰¹å¾å·¥ç¨‹"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.label_encoders = {}
        self.feature_columns = []
        
    def load_data(self, file_path):
        """åŠ è½½æ•°æ®"""
        try:
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path)
            elif file_path.endswith('.xlsx'):
                df = pd.read_excel(file_path)
            else:
                raise ValueError("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: CSV, XLSX")
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {df.shape[0]}è¡Œ, {df.shape[1]}åˆ—")
            return df
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None
    
    def validate_required_fields(self, df):
        """éªŒè¯å¿…éœ€å­—æ®µ"""
        required_fields = [
            'patient_id', 'age', 'sex', 'chief_complaint',
            'ALT', 'AST', 'AFP', 'imaging_result'
        ]
        
        missing_fields = [field for field in required_fields if field not in df.columns]
        
        if missing_fields:
            print(f"âš ï¸  ç¼ºå¤±å¿…éœ€å­—æ®µ: {missing_fields}")
            return False
        
        print("âœ… å¿…éœ€å­—æ®µéªŒè¯é€šè¿‡")
        return True
    
    def clean_data(self, df):
        """æ•°æ®æ¸…æ´—"""
        print("ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—...")
        
        # 1. å¤„ç†é‡å¤è®°å½•
        initial_rows = len(df)
        df = df.drop_duplicates(subset=['patient_id'])
        print(f"   ç§»é™¤é‡å¤è®°å½•: {initial_rows - len(df)}æ¡")
        
        # 2. å¤„ç†å¼‚å¸¸å€¼
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        for col in numeric_columns:
            if col in ['age', 'ALT', 'AST', 'AFP']:
                # ä½¿ç”¨IQRæ–¹æ³•å¤„ç†å¼‚å¸¸å€¼
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
                if outliers > 0:
                    print(f"   {col}: å‘ç°{outliers}ä¸ªå¼‚å¸¸å€¼")
                    # ç”¨è¾¹ç•Œå€¼æ›¿æ¢å¼‚å¸¸å€¼
                    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)
        
        # 3. å¤„ç†ç¼ºå¤±å€¼
        missing_info = df.isnull().sum()
        if missing_info.sum() > 0:
            print("   ç¼ºå¤±å€¼æƒ…å†µ:")
            for col, missing_count in missing_info[missing_info > 0].items():
                missing_rate = missing_count / len(df) * 100
                print(f"     {col}: {missing_count}æ¡ ({missing_rate:.1f}%)")
        
        print("âœ… æ•°æ®æ¸…æ´—å®Œæˆ")
        return df
    
    def feature_engineering(self, df):
        """ç‰¹å¾å·¥ç¨‹"""
        print("ğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹...")
        
        # 1. åˆ›å»ºå¹´é¾„åˆ†ç»„
        df['age_group'] = pd.cut(df['age'], bins=[0, 40, 60, 80, 100], 
                                labels=['é’å¹´', 'ä¸­å¹´', 'è€å¹´', 'é«˜é¾„'])
        
        # 2. AFPåˆ†çº§
        if 'AFP' in df.columns:
            df['AFP_level'] = pd.cut(df['AFP'], bins=[0, 20, 400, float('inf')], 
                                   labels=['æ­£å¸¸', 'è½»åº¦å‡é«˜', 'æ˜¾è‘—å‡é«˜'])
        
        # 3. è‚åŠŸèƒ½ç»¼åˆè¯„åˆ†
        if all(col in df.columns for col in ['ALT', 'AST']):
            df['liver_function_score'] = (df['ALT'] / 40 + df['AST'] / 40) / 2
        
        # 4. æ–‡æœ¬ç‰¹å¾å¤„ç†ï¼ˆç—‡çŠ¶æè¿°ï¼‰
        if 'chief_complaint' in df.columns:
            # æå–å…³é”®ç—‡çŠ¶
            symptoms = ['ç–¼ç—›', 'ä¹åŠ›', 'é£Ÿæ¬²å‡é€€', 'ä½“é‡ä¸‹é™', 'è…¹èƒ€', 'é»„ç–¸']
            for symptom in symptoms:
                df[f'has_{symptom}'] = df['chief_complaint'].str.contains(symptom, na=False).astype(int)
        
        # 5. å½±åƒç‰¹å¾æå–
        if 'imaging_result' in df.columns:
            imaging_features = ['å ä½', 'è¾¹ç•Œä¸æ¸…', 'å¼ºåŒ–', 'é—¨é™è„‰', 'è½¬ç§»']
            for feature in imaging_features:
                df[f'imaging_{feature}'] = df['imaging_result'].str.contains(feature, na=False).astype(int)
        
        print("âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ")
        return df
    
    def prepare_ml_data(self, df, target_column):
        """å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ®"""
        print("ğŸ“Š å‡†å¤‡æœºå™¨å­¦ä¹ æ•°æ®...")
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
        feature_columns = [col for col in df.columns 
                          if col not in ['patient_id', target_column, 'chief_complaint', 'imaging_result']]
        
        X = df[feature_columns].copy()
        y = df[target_column].copy()
        
        # å¤„ç†åˆ†ç±»å˜é‡
        categorical_columns = X.select_dtypes(include=['object', 'category']).columns
        for col in categorical_columns:
            if col not in self.label_encoders:
                self.label_encoders[col] = LabelEncoder()
                X[col] = self.label_encoders[col].fit_transform(X[col].fillna('unknown'))
            else:
                X[col] = self.label_encoders[col].transform(X[col].fillna('unknown'))
        
        # å¤„ç†æ•°å€¼å˜é‡ç¼ºå¤±å€¼
        numeric_columns = X.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) > 0:
            imputer = SimpleImputer(strategy='median')
            X[numeric_columns] = imputer.fit_transform(X[numeric_columns])
        
        # æ ‡å‡†åŒ–æ•°å€¼ç‰¹å¾
        X[numeric_columns] = self.scaler.fit_transform(X[numeric_columns])
        
        self.feature_columns = feature_columns
        
        print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: {X.shape[0]}æ ·æœ¬, {X.shape[1]}ç‰¹å¾")
        return X, y


class EDAAnalyzer:
    """æ¢ç´¢æ€§æ•°æ®åˆ†æ"""
    
    def __init__(self):
        plt.style.use('seaborn-v0_8')
        
    def basic_info(self, df):
        """åŸºç¡€ä¿¡æ¯åˆ†æ"""
        print("ğŸ“‹ æ•°æ®åŸºç¡€ä¿¡æ¯:")
        print(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"   æ•°æ®ç±»å‹åˆ†å¸ƒ:")
        print(f"     æ•°å€¼å‹: {len(df.select_dtypes(include=[np.number]).columns)}åˆ—")
        print(f"     æ–‡æœ¬å‹: {len(df.select_dtypes(include=['object']).columns)}åˆ—")
        print(f"     æ—¥æœŸå‹: {len(df.select_dtypes(include=['datetime']).columns)}åˆ—")
        
        # ç¼ºå¤±å€¼ç»Ÿè®¡
        missing_stats = df.isnull().sum().sort_values(ascending=False)
        if missing_stats.sum() > 0:
            print("\n   ç¼ºå¤±å€¼ç»Ÿè®¡:")
            for col, missing in missing_stats[missing_stats > 0].head(10).items():
                rate = missing / len(df) * 100
                print(f"     {col}: {missing}æ¡ ({rate:.1f}%)")
        
        return {
            'shape': df.shape,
            'missing_stats': missing_stats.to_dict(),
            'dtypes': df.dtypes.to_dict()
        }
    
    def plot_distributions(self, df, save_path=None):
        """ç»˜åˆ¶æ•°å€¼å˜é‡åˆ†å¸ƒå›¾"""
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        n_cols = min(4, len(numeric_columns))
        n_rows = (len(numeric_columns) + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))
        axes = axes.flatten() if n_rows > 1 else [axes]
        
        for i, col in enumerate(numeric_columns):
            if i < len(axes):
                df[col].hist(bins=30, ax=axes[i], alpha=0.7)
                axes[i].set_title(f'{col}åˆ†å¸ƒ')
                axes[i].set_xlabel(col)
                axes[i].set_ylabel('é¢‘æ¬¡')
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(numeric_columns), len(axes)):
            axes[i].set_visible(False)
        
        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()
    
    def correlation_analysis(self, df, save_path=None):
        """ç›¸å…³æ€§åˆ†æ"""
        numeric_df = df.select_dtypes(include=[np.number])
        
        if len(numeric_df.columns) > 1:
            corr_matrix = numeric_df.corr()
            
            plt.figure(figsize=(12, 10))
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
                       square=True, fmt='.2f')
            plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
            
            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.show()
            
            return corr_matrix
        
        return None
    
    def survival_analysis_eda(self, df, duration_col='survival_months', event_col='death_event'):
        """ç”Ÿå­˜åˆ†æEDA"""
        if duration_col not in df.columns or event_col not in df.columns:
            print(f"âš ï¸  ç¼ºå°‘ç”Ÿå­˜åˆ†æå¿…éœ€å­—æ®µ: {duration_col}, {event_col}")
            return None
        
        print("ğŸ“Š ç”Ÿå­˜åˆ†æEDA:")
        
        # åŸºç¡€ç»Ÿè®¡
        total_patients = len(df)
        events = df[event_col].sum()
        censored = total_patients - events
        
        print(f"   æ€»æ‚£è€…æ•°: {total_patients}")
        print(f"   äº‹ä»¶å‘ç”Ÿ: {events} ({events/total_patients*100:.1f}%)")
        print(f"   åˆ å¤±: {censored} ({censored/total_patients*100:.1f}%)")
        
        # ç”Ÿå­˜æ—¶é—´ç»Ÿè®¡
        print(f"   éšè®¿æ—¶é—´: ä¸­ä½æ•°{df[duration_col].median():.1f}æœˆ")
        print(f"   éšè®¿èŒƒå›´: {df[duration_col].min():.1f} - {df[duration_col].max():.1f}æœˆ")
        
        # ç»˜åˆ¶ç”Ÿå­˜æ—¶é—´åˆ†å¸ƒ
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))
        
        # ç”Ÿå­˜æ—¶é—´ç›´æ–¹å›¾
        df[duration_col].hist(bins=30, ax=axes[0], alpha=0.7)
        axes[0].set_title('ç”Ÿå­˜æ—¶é—´åˆ†å¸ƒ')
        axes[0].set_xlabel('ç”Ÿå­˜æ—¶é—´(æœˆ)')
        axes[0].set_ylabel('æ‚£è€…æ•°')
        
        # äº‹ä»¶å‘ç”Ÿæ—¶é—´
        event_times = df[df[event_col] == 1][duration_col]
        if len(event_times) > 0:
            event_times.hist(bins=20, ax=axes[1], alpha=0.7, color='red')
            axes[1].set_title('äº‹ä»¶å‘ç”Ÿæ—¶é—´åˆ†å¸ƒ')
            axes[1].set_xlabel('äº‹ä»¶æ—¶é—´(æœˆ)')
            axes[1].set_ylabel('äº‹ä»¶æ•°')
        
        plt.tight_layout()
        plt.show()
        
        return {
            'total_patients': total_patients,
            'events': events,
            'event_rate': events/total_patients,
            'median_followup': df[duration_col].median(),
            'followup_range': (df[duration_col].min(), df[duration_col].max())
        }
    
    def generate_eda_report(self, df, output_path="eda_report.html"):
        """ç”ŸæˆEDAæŠ¥å‘Š"""
        print("ğŸ“ˆ ç”ŸæˆEDAæŠ¥å‘Š...")
        
        basic_stats = self.basic_info(df)
        
        # åˆ›å»ºHTMLæŠ¥å‘Š
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>æ¢ç´¢æ€§æ•°æ®åˆ†ææŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .header {{ background-color: #f0f8ff; padding: 20px; border-radius: 10px; }}
                .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #1f77b4; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ğŸ¥ åŒ»ç–—æ•°æ®æ¢ç´¢æ€§åˆ†ææŠ¥å‘Š</h1>
                <p>ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <div class="section">
                <h2>ğŸ“Š æ•°æ®åŸºç¡€ä¿¡æ¯</h2>
                <p><strong>æ•°æ®å½¢çŠ¶:</strong> {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—</p>
                <p><strong>æ•°å€¼å‹å˜é‡:</strong> {len(df.select_dtypes(include=[np.number]).columns)}ä¸ª</p>
                <p><strong>æ–‡æœ¬å‹å˜é‡:</strong> {len(df.select_dtypes(include=['object']).columns)}ä¸ª</p>
            </div>
            
            <div class="section">
                <h2>ğŸ“‹ å˜é‡ç»Ÿè®¡æ‘˜è¦</h2>
                {df.describe().to_html()}
            </div>
            
            <div class="section">
                <h2>ğŸ” ç¼ºå¤±å€¼åˆ†æ</h2>
                {df.isnull().sum().to_frame('ç¼ºå¤±æ•°é‡').to_html()}
            </div>
        </body>
        </html>
        """
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ… EDAæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
        return output_path


def create_sample_dataset(n_patients=500, save_path="sample_medical_data.csv"):
    """åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ•°æ®é›†"""
    print(f"ğŸ”¬ åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ•°æ®é›† ({n_patients}ä¸ªæ‚£è€…)...")
    
    np.random.seed(42)
    
    # åŸºç¡€ä¿¡æ¯
    data = {
        'patient_id': [f'P{i:04d}' for i in range(1, n_patients+1)],
        'age': np.random.normal(60, 15, n_patients).clip(20, 90),
        'sex': np.random.choice(['ç”·', 'å¥³'], n_patients),
        'weight': np.random.normal(65, 12, n_patients).clip(40, 120),
    }
    
    # åˆå¹¶ç–¾ç—…
    data['hypertension'] = np.random.choice([0, 1], n_patients, p=[0.7, 0.3])
    data['diabetes'] = np.random.choice([0, 1], n_patients, p=[0.8, 0.2])
    
    # å®éªŒå®¤æ£€æŸ¥
    data['ALT'] = np.random.lognormal(3.5, 0.8, n_patients).clip(10, 500)
    data['AST'] = np.random.lognormal(3.4, 0.7, n_patients).clip(10, 400)
    data['AFP'] = np.random.lognormal(2.5, 2.0, n_patients).clip(1, 10000)
    data['albumin'] = np.random.normal(40, 8, n_patients).clip(20, 60)
    data['bilirubin'] = np.random.lognormal(2.5, 0.8, n_patients).clip(5, 200)
    
    # å½±åƒç‰¹å¾
    tumor_sizes = np.random.lognormal(1.2, 0.8, n_patients).clip(0.5, 15)
    data['tumor_size_cm'] = tumor_sizes
    data['portal_vein_invasion'] = np.random.choice([0, 1], n_patients, p=[0.75, 0.25])
    data['lymph_node_metastasis'] = np.random.choice([0, 1], n_patients, p=[0.8, 0.2])
    
    # ç—…ç†åˆ†çº§ï¼ˆå¦‚æœæœ‰æ‰‹æœ¯ï¼‰
    data['histologic_grade'] = np.random.choice(['ä½åˆ†åŒ–', 'ä¸­åˆ†åŒ–', 'é«˜åˆ†åŒ–'], n_patients, p=[0.3, 0.5, 0.2])
    
    # æ²»ç–—ä¿¡æ¯
    data['surgery_type'] = np.random.choice(['è‚å¶åˆ‡é™¤', 'è‚æ®µåˆ‡é™¤', 'å±€éƒ¨åˆ‡é™¤'], n_patients, p=[0.4, 0.4, 0.2])
    data['r0_resection'] = np.random.choice([0, 1], n_patients, p=[0.2, 0.8])
    
    # ç”Ÿå­˜ç»“å±€ï¼ˆæ¨¡æ‹Ÿï¼‰
    # åŸºäºé£é™©å› ç´ è®¡ç®—ç”Ÿå­˜æ—¶é—´
    risk_score = (
        (data['age'] > 65).astype(int) * 0.3 +
        (tumor_sizes > 5).astype(int) * 0.4 +
        data['portal_vein_invasion'] * 0.5 +
        (data['AFP'] > 400).astype(int) * 0.3 +
        data['lymph_node_metastasis'] * 0.6
    )
    
    # ç”Ÿæˆç”Ÿå­˜æ—¶é—´ï¼ˆæœˆï¼‰
    base_survival = 36  # åŸºç¡€ä¸­ä½ç”Ÿå­˜36ä¸ªæœˆ
    survival_months = np.random.exponential(base_survival * np.exp(-risk_score))
    data['survival_months'] = survival_months.clip(1, 120)
    
    # ç”Ÿæˆäº‹ä»¶æ ‡å¿—ï¼ˆæ­»äº¡/åˆ å¤±ï¼‰
    # é«˜é£é™©æ‚£è€…æ›´å¯èƒ½å‘ç”Ÿäº‹ä»¶
    event_prob = 0.3 + risk_score * 0.4
    data['death_event'] = np.random.binomial(1, event_prob.clip(0, 0.8), n_patients)
    
    # å¤å‘ä¿¡æ¯
    recurrence_prob = 0.2 + risk_score * 0.3
    data['recurrence'] = np.random.binomial(1, recurrence_prob.clip(0, 0.7), n_patients)
    data['recurrence_months'] = np.where(
        data['recurrence'] == 1,
        np.random.exponential(18) * (1 - risk_score * 0.3),
        np.nan
    ).clip(1, data['survival_months'])
    
    # ç—‡çŠ¶æè¿°ï¼ˆæ–‡æœ¬ï¼‰
    symptoms_templates = [
        "å³ä¸Šè…¹ç–¼ç—›{duration}ï¼Œä¼´é£Ÿæ¬²å‡é€€",
        "è…¹èƒ€ä¸é€‚{duration}ï¼Œä½“é‡ä¸‹é™",
        "ä¹åŠ›{duration}ï¼Œå¶æœ‰ä½çƒ­",
        "å³ä¸Šè…¹éšç—›{duration}ï¼Œä¼´æ¶å¿ƒ",
        "é£Ÿæ¬²ä¸æŒ¯{duration}ï¼Œè…¹éƒ¨ä¸é€‚"
    ]
    
    durations = ["3å‘¨", "1æœˆ", "2æœˆ", "3æœˆ", "åŠå¹´"]
    data['chief_complaint'] = [
        np.random.choice(symptoms_templates).format(duration=np.random.choice(durations))
        for _ in range(n_patients)
    ]
    
    # å½±åƒæè¿°
    imaging_templates = [
        "CTæç¤ºè‚{location}å ä½ï¼Œå¤§å°çº¦{size}cmï¼Œ{enhancement}ï¼Œ{invasion}",
        "MRIæ˜¾ç¤ºè‚{location}å¼‚å¸¸ä¿¡å·ï¼Œ{size}cmï¼Œ{enhancement}ï¼Œ{invasion}",
        "è¶…å£°å‘ç°è‚{location}ä½å›å£°åŒºï¼Œ{size}cmï¼Œ{enhancement}ï¼Œ{invasion}"
    ]
    
    locations = ["å³å¶", "å·¦å¶", "å·¦å³å¶"]
    enhancements = ["ä¸å‡åŒ€å¼ºåŒ–", "ç¯å½¢å¼ºåŒ–", "æ¸è¿›æ€§å¼ºåŒ–"]
    invasions = ["é—¨é™è„‰æ— ä¾µçŠ¯", "é—¨é™è„‰å—ä¾µ", "èƒ†ç®¡å—ä¾µ"]
    
    data['imaging_result'] = [
        np.random.choice(imaging_templates).format(
            location=np.random.choice(locations),
            size=f"{tumor_sizes[i]:.1f}",
            enhancement=np.random.choice(enhancements),
            invasion=np.random.choice(invasions)
        )
        for i in range(n_patients)
    ]
    
    # åˆ›å»ºDataFrame
    df = pd.DataFrame(data)
    
    # ä¿å­˜æ•°æ®
    df.to_csv(save_path, index=False, encoding='utf-8')
    print(f"âœ… ç¤ºä¾‹æ•°æ®é›†å·²ä¿å­˜: {save_path}")
    
    return df
