"""
ç”Ÿå­˜åˆ†ææ¨¡å— - Coxå›å½’ã€ç”Ÿå­˜é¢„æµ‹ã€é£é™©åˆ†å±‚
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from lifelines import CoxPHFitter, KaplanMeierFitter
from lifelines.utils import concordance_index
from lifelines.statistics import logrank_test
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

class SurvivalAnalyzer:
    """ç”Ÿå­˜åˆ†æå™¨"""
    
    def __init__(self):
        self.cox_model = None
        self.km_fitter = None
        self.feature_names = None
        self.training_results = {}
        
    def prepare_survival_data(self, df, duration_col='survival_months', event_col='death_event'):
        """å‡†å¤‡ç”Ÿå­˜åˆ†ææ•°æ®"""
        print("ğŸ“Š å‡†å¤‡ç”Ÿå­˜åˆ†ææ•°æ®...")
        
        # éªŒè¯å¿…éœ€åˆ—
        if duration_col not in df.columns:
            raise ValueError(f"ç¼ºå°‘ç”Ÿå­˜æ—¶é—´åˆ—: {duration_col}")
        if event_col not in df.columns:
            raise ValueError(f"ç¼ºå°‘äº‹ä»¶åˆ—: {event_col}")
        
        # æ•°æ®éªŒè¯
        if df[duration_col].isnull().any():
            print("âš ï¸  ç”Ÿå­˜æ—¶é—´å­˜åœ¨ç¼ºå¤±å€¼ï¼Œå°†è¢«ç§»é™¤")
            df = df.dropna(subset=[duration_col])
        
        if df[event_col].isnull().any():
            print("âš ï¸  äº‹ä»¶æ ‡å¿—å­˜åœ¨ç¼ºå¤±å€¼ï¼Œå°†è¢«ç§»é™¤")
            df = df.dropna(subset=[event_col])
        
        # ç¡®ä¿æ—¶é—´ä¸ºæ­£æ•°
        if (df[duration_col] <= 0).any():
            print("âš ï¸  å‘ç°éæ­£æ•°ç”Ÿå­˜æ—¶é—´ï¼Œå°†è¢«ä¿®æ­£")
            df = df[df[duration_col] > 0]
        
        # ç¡®ä¿äº‹ä»¶ä¸º0/1
        unique_events = df[event_col].unique()
        if not set(unique_events).issubset({0, 1}):
            print(f"âš ï¸  äº‹ä»¶åˆ—åŒ…å«é0/1å€¼: {unique_events}")
            df[event_col] = df[event_col].astype(int)
        
        print(f"âœ… ç”Ÿå­˜æ•°æ®å‡†å¤‡å®Œæˆ: {len(df)}ä¸ªæ ·æœ¬")
        print(f"   äº‹ä»¶å‘ç”Ÿç‡: {df[event_col].mean():.2%}")
        print(f"   ä¸­ä½éšè®¿æ—¶é—´: {df[duration_col].median():.1f}æœˆ")
        
        return df
    
    def kaplan_meier_analysis(self, df, duration_col='survival_months', event_col='death_event', 
                            group_col=None, save_plot=None):
        """Kaplan-Meierç”Ÿå­˜åˆ†æ"""
        print("ğŸ“ˆ è¿›è¡ŒKaplan-Meierç”Ÿå­˜åˆ†æ...")
        
        self.km_fitter = KaplanMeierFitter()
        
        plt.figure(figsize=(12, 6))
        
        if group_col and group_col in df.columns:
            # åˆ†ç»„ç”Ÿå­˜åˆ†æ
            groups = df[group_col].unique()
            
            for group in groups:
                group_data = df[df[group_col] == group]
                self.km_fitter.fit(
                    group_data[duration_col],
                    group_data[event_col],
                    label=f'{group_col}={group}'
                )
                self.km_fitter.plot_survival_function()
            
            # è¿›è¡Œlog-rankæ£€éªŒ
            if len(groups) == 2:
                group1 = df[df[group_col] == groups[0]]
                group2 = df[df[group_col] == groups[1]]
                
                logrank_result = logrank_test(
                    group1[duration_col], group2[duration_col],
                    group1[event_col], group2[event_col]
                )
                
                plt.title(f'Kaplan-Meierç”Ÿå­˜æ›²çº¿\nLog-rank på€¼: {logrank_result.p_value:.4f}')
            else:
                plt.title('Kaplan-Meierç”Ÿå­˜æ›²çº¿ï¼ˆåˆ†ç»„æ¯”è¾ƒï¼‰')
        else:
            # æ•´ä½“ç”Ÿå­˜åˆ†æ
            self.km_fitter.fit(df[duration_col], df[event_col], label='æ•´ä½“äººç¾¤')
            self.km_fitter.plot_survival_function()
            
            median_survival = self.km_fitter.median_survival_time_
            plt.title(f'Kaplan-Meierç”Ÿå­˜æ›²çº¿\nä¸­ä½ç”Ÿå­˜æ—¶é—´: {median_survival:.1f}æœˆ')
        
        plt.xlabel('æ—¶é—´ (æœˆ)')
        plt.ylabel('ç”Ÿå­˜æ¦‚ç‡')
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        if save_plot:
            plt.savefig(save_plot, dpi=300, bbox_inches='tight')
        plt.show()
        
        return self.km_fitter
    
    def cox_regression(self, df, duration_col='survival_months', event_col='death_event', 
                      exclude_cols=None):
        """Coxæ¯”ä¾‹é£é™©å›å½’"""
        print("ğŸ”¬ è¿›è¡ŒCoxæ¯”ä¾‹é£é™©å›å½’åˆ†æ...")
        
        # å‡†å¤‡æ•°æ®
        exclude_cols = exclude_cols or ['patient_id', 'chief_complaint', 'imaging_result']
        feature_cols = [col for col in df.columns 
                       if col not in exclude_cols + [duration_col, event_col]]
        
        # åˆ›å»ºåˆ†ææ•°æ®æ¡†
        analysis_df = df[feature_cols + [duration_col, event_col]].copy()
        
        # å¤„ç†åˆ†ç±»å˜é‡
        for col in analysis_df.columns:
            if analysis_df[col].dtype == 'object':
                analysis_df[col] = pd.Categorical(analysis_df[col]).codes
        
        # é‡å‘½ååˆ—ä»¥ç¬¦åˆlifelinesè¦æ±‚
        analysis_df = analysis_df.rename(columns={
            duration_col: 'T',
            event_col: 'E'
        })
        
        # æ‹ŸåˆCoxæ¨¡å‹
        self.cox_model = CoxPHFitter()
        self.cox_model.fit(analysis_df, duration_col='T', event_col='E')
        
        # è¾“å‡ºç»“æœ
        print("\nğŸ“Š Coxå›å½’ç»“æœ:")
        self.cox_model.print_summary()
        
        # è®¡ç®—C-index
        c_index = self.cox_model.concordance_index_
        print(f"\nâœ… C-index (ä¸€è‡´æ€§æŒ‡æ•°): {c_index:.4f}")
        
        # ä¿å­˜ç‰¹å¾åç§°
        self.feature_names = feature_cols
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        self.training_results = {
            'c_index': c_index,
            'feature_names': feature_cols,
            'n_samples': len(analysis_df),
            'event_rate': analysis_df['E'].mean()
        }
        
        return self.cox_model
    
    def predict_survival(self, X, times=None):
        """é¢„æµ‹ç”Ÿå­˜æ¦‚ç‡"""
        if self.cox_model is None:
            raise ValueError("Coxæ¨¡å‹å°šæœªè®­ç»ƒ")
        
        if times is None:
            times = [12, 24, 36, 60]  # 1å¹´ã€2å¹´ã€3å¹´ã€5å¹´
        
        # ç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
        if hasattr(X, 'columns') and self.feature_names:
            X = X[self.feature_names]
        
        # é¢„æµ‹ç”Ÿå­˜å‡½æ•°
        survival_functions = self.cox_model.predict_survival_function(X)
        
        predictions = {}
        for time in times:
            predictions[f'survival_prob_{time}m'] = [
                sf(time) if time <= sf.timeline.max() else np.nan 
                for sf in survival_functions
            ]
        
        # é¢„æµ‹ä¸­ä½ç”Ÿå­˜æ—¶é—´
        median_survival = self.cox_model.predict_median(X)
        predictions['median_survival_months'] = median_survival
        
        # é£é™©åˆ†å±‚
        risk_scores = self.cox_model.predict_partial_hazard(X)
        risk_quartiles = np.percentile(risk_scores, [25, 50, 75])
        
        risk_groups = []
        for score in risk_scores:
            if score <= risk_quartiles[0]:
                risk_groups.append('ä½å±')
            elif score <= risk_quartiles[1]:
                risk_groups.append('ä¸­ä½å±')
            elif score <= risk_quartiles[2]:
                risk_groups.append('ä¸­é«˜å±')
            else:
                risk_groups.append('é«˜å±')
        
        predictions['risk_group'] = risk_groups
        predictions['risk_score'] = risk_scores
        
        return predictions
    
    def plot_survival_curves(self, df, duration_col='survival_months', event_col='death_event',
                           risk_groups=None, save_plot=None):
        """ç»˜åˆ¶ç”Ÿå­˜æ›²çº¿"""
        plt.figure(figsize=(12, 8))
        
        if risk_groups is not None:
            # æŒ‰é£é™©åˆ†ç»„ç»˜åˆ¶
            unique_groups = np.unique(risk_groups)
            colors = ['green', 'yellow', 'orange', 'red']
            
            for i, group in enumerate(unique_groups):
                group_mask = risk_groups == group
                group_data = df[group_mask]
                
                kmf = KaplanMeierFitter()
                kmf.fit(
                    group_data[duration_col],
                    group_data[event_col],
                    label=f'{group} (n={len(group_data)})'
                )
                
                kmf.plot_survival_function(color=colors[i % len(colors)])
        else:
            # æ•´ä½“ç”Ÿå­˜æ›²çº¿
            kmf = KaplanMeierFitter()
            kmf.fit(df[duration_col], df[event_col], label=f'æ•´ä½“ (n={len(df)})')
            kmf.plot_survival_function()
        
        plt.xlabel('æ—¶é—´ (æœˆ)')
        plt.ylabel('ç”Ÿå­˜æ¦‚ç‡')
        plt.title('ç”Ÿå­˜æ›²çº¿åˆ†æ')
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        if save_plot:
            plt.savefig(save_plot, dpi=300, bbox_inches='tight')
        plt.show()
    
    def validate_model(self, df, duration_col='survival_months', event_col='death_event', 
                      test_size=0.2):
        """æ¨¡å‹éªŒè¯"""
        print("ğŸ” è¿›è¡Œæ¨¡å‹éªŒè¯...")
        
        if self.cox_model is None:
            raise ValueError("Coxæ¨¡å‹å°šæœªè®­ç»ƒ")
        
        # åˆ†å‰²æ•°æ®
        train_df, test_df = train_test_split(df, test_size=test_size, random_state=42)
        
        # åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—C-index
        test_features = test_df[self.feature_names]
        test_duration = test_df[duration_col]
        test_event = test_df[event_col]
        
        # å¤„ç†åˆ†ç±»å˜é‡
        for col in test_features.columns:
            if test_features[col].dtype == 'object':
                test_features[col] = pd.Categorical(test_features[col]).codes
        
        # é¢„æµ‹é£é™©åˆ†æ•°
        risk_scores = self.cox_model.predict_partial_hazard(test_features)
        
        # è®¡ç®—æµ‹è¯•é›†C-index
        test_c_index = concordance_index(test_duration, -risk_scores, test_event)
        
        print(f"âœ… æµ‹è¯•é›†C-index: {test_c_index:.4f}")
        
        # æ ¡å‡†åˆ†æ
        self._calibration_analysis(test_df, duration_col, event_col)
        
        return {
            'test_c_index': test_c_index,
            'train_c_index': self.training_results.get('c_index'),
            'test_size': len(test_df)
        }
    
    def _calibration_analysis(self, df, duration_col, event_col, time_points=[12, 24, 36]):
        """æ ¡å‡†åˆ†æ"""
        print("ğŸ“ è¿›è¡Œæ¨¡å‹æ ¡å‡†åˆ†æ...")
        
        # é¢„æµ‹ä¸åŒæ—¶é—´ç‚¹çš„ç”Ÿå­˜æ¦‚ç‡
        features = df[self.feature_names]
        
        # å¤„ç†åˆ†ç±»å˜é‡
        for col in features.columns:
            if features[col].dtype == 'object':
                features[col] = pd.Categorical(features[col]).codes
        
        predictions = self.predict_survival(features, times=time_points)
        
        # è®¡ç®—å®é™…ç”Ÿå­˜ç‡
        for time_point in time_points:
            pred_col = f'survival_prob_{time_point}m'
            if pred_col in predictions:
                # å®é™…åœ¨è¯¥æ—¶é—´ç‚¹çš„ç”Ÿå­˜çŠ¶æ€
                actual_survival = ((df[duration_col] > time_point) | 
                                 ((df[duration_col] <= time_point) & (df[event_col] == 0)))
                
                pred_survival = predictions[pred_col]
                
                # ç®€å•æ ¡å‡†åˆ†æ
                valid_idx = ~np.isnan(pred_survival)
                if valid_idx.sum() > 0:
                    correlation = np.corrcoef(
                        actual_survival[valid_idx].astype(float),
                        pred_survival[valid_idx]
                    )[0, 1]
                    
                    print(f"   {time_point}æœˆç”Ÿå­˜é¢„æµ‹ç›¸å…³æ€§: {correlation:.3f}")


class DeepSurvivalAnalyzer:
    """æ·±åº¦å­¦ä¹ ç”Ÿå­˜åˆ†æï¼ˆåŸºäºDeepSurvæ¦‚å¿µçš„ç®€åŒ–å®ç°ï¼‰"""
    
    def __init__(self, hidden_layers=[64, 32], dropout_rate=0.3):
        self.hidden_layers = hidden_layers
        self.dropout_rate = dropout_rate
        self.model = None
        
    def build_model(self, input_dim):
        """æ„å»ºç¥ç»ç½‘ç»œæ¨¡å‹"""
        try:
            import tensorflow as tf
            from tensorflow.keras.models import Sequential
            from tensorflow.keras.layers import Dense, Dropout
            from tensorflow.keras.regularizers import l2
            
            model = Sequential()
            
            # è¾“å…¥å±‚
            model.add(Dense(self.hidden_layers[0], input_dim=input_dim, 
                          activation='relu', kernel_regularizer=l2(0.01)))
            model.add(Dropout(self.dropout_rate))
            
            # éšè—å±‚
            for units in self.hidden_layers[1:]:
                model.add(Dense(units, activation='relu', kernel_regularizer=l2(0.01)))
                model.add(Dropout(self.dropout_rate))
            
            # è¾“å‡ºå±‚ï¼ˆçº¿æ€§æ¿€æ´»ç”¨äºé£é™©é¢„æµ‹ï¼‰
            model.add(Dense(1, activation='linear'))
            
            self.model = model
            print("âœ… æ·±åº¦ç”Ÿå­˜æ¨¡å‹æ„å»ºå®Œæˆ")
            return model
            
        except ImportError:
            print("âŒ éœ€è¦å®‰è£…TensorFlow: pip install tensorflow")
            return None
    
    def train(self, X, duration, event, epochs=100, batch_size=32):
        """è®­ç»ƒæ·±åº¦ç”Ÿå­˜æ¨¡å‹"""
        if self.model is None:
            self.build_model(X.shape[1])
        
        try:
            # è¿™é‡Œéœ€è¦å®ç°è‡ªå®šä¹‰çš„CoxæŸå¤±å‡½æ•°
            # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨æ’åºæŸå¤±
            print("ğŸš€ å¼€å§‹è®­ç»ƒæ·±åº¦ç”Ÿå­˜æ¨¡å‹...")
            print("ğŸ’¡ æ³¨æ„ï¼šè¿™æ˜¯ç®€åŒ–å®ç°ï¼Œå®Œæ•´ç‰ˆéœ€è¦ä¸“é—¨çš„CoxæŸå¤±å‡½æ•°")
            
            # åˆ›å»ºæ’åºæ ‡ç­¾ï¼ˆç”Ÿå­˜æ—¶é—´æ’åºï¼‰
            sort_idx = np.argsort(-duration)  # æŒ‰ç”Ÿå­˜æ—¶é—´é™åºæ’åº
            y_rank = np.zeros(len(duration))
            y_rank[sort_idx] = np.arange(len(duration))
            y_rank = y_rank / len(duration)  # å½’ä¸€åŒ–åˆ°[0,1]
            
            # ç¼–è¯‘æ¨¡å‹
            self.model.compile(optimizer='adam', loss='mse', metrics=['mae'])
            
            # è®­ç»ƒ
            history = self.model.fit(
                X, y_rank,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=0.2,
                verbose=1
            )
            
            print("âœ… æ·±åº¦ç”Ÿå­˜æ¨¡å‹è®­ç»ƒå®Œæˆ")
            return history
            
        except Exception as e:
            print(f"âŒ æ·±åº¦æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return None


def create_survival_pipeline(data_path, duration_col='survival_months', 
                           event_col='death_event', model_type='cox'):
    """åˆ›å»ºå®Œæ•´çš„ç”Ÿå­˜åˆ†ææµæ°´çº¿"""
    print("ğŸ”¬ å¯åŠ¨ç”Ÿå­˜åˆ†ææµæ°´çº¿...")
    
    # 1. åŠ è½½æ•°æ®
    from .data_engineering import DataProcessor
    processor = DataProcessor()
    
    df = processor.load_data(data_path)
    if df is None:
        return None
    
    # 2. æ•°æ®æ¸…æ´—
    df_clean = processor.clean_data(df)
    df_features = processor.feature_engineering(df_clean)
    
    # 3. ç”Ÿå­˜åˆ†æ
    analyzer = SurvivalAnalyzer()
    survival_df = analyzer.prepare_survival_data(df_features, duration_col, event_col)
    
    # 4. Kaplan-Meieråˆ†æ
    km_fitter = analyzer.kaplan_meier_analysis(survival_df, duration_col, event_col)
    
    # 5. Coxå›å½’
    cox_model = analyzer.cox_regression(survival_df, duration_col, event_col)
    
    # 6. æ¨¡å‹éªŒè¯
    validation_results = analyzer.validate_model(survival_df, duration_col, event_col)
    
    # 7. ä¿å­˜æ¨¡å‹
    import joblib
    from datetime import datetime
    model_path = f"models/survival_cox_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
    
    model_data = {
        'cox_model': cox_model,
        'analyzer': analyzer,
        'validation_results': validation_results,
        'feature_names': analyzer.feature_names
    }
    
    joblib.dump(model_data, model_path)
    print(f"âœ… ç”Ÿå­˜æ¨¡å‹å·²ä¿å­˜: {model_path}")
    
    return {
        'analyzer': analyzer,
        'cox_model': cox_model,
        'validation_results': validation_results,
        'model_path': model_path
    }
