"""
å¤å‘é¢„æµ‹æ¨¡å— - æœ¯åå¤å‘å’Œè½¬ç§»é¢„æµ‹
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, classification_report
import xgboost as xgb
import lightgbm as lgb
import matplotlib.pyplot as plt
from datetime import datetime

class RecurrencePredictor:
    """å¤å‘é¢„æµ‹å™¨"""
    
    def __init__(self, model_type='xgboost', prediction_window=24):
        self.model_type = model_type
        self.prediction_window = prediction_window  # é¢„æµ‹çª—å£ï¼ˆæœˆï¼‰
        self.model = None
        self.feature_names = None
        self.training_results = {}
        
    def prepare_recurrence_data(self, df, recurrence_col='recurrence', 
                              recurrence_time_col='recurrence_months'):
        """å‡†å¤‡å¤å‘é¢„æµ‹æ•°æ®"""
        print(f"ğŸ“Š å‡†å¤‡å¤å‘é¢„æµ‹æ•°æ®ï¼ˆé¢„æµ‹çª—å£ï¼š{self.prediction_window}æœˆï¼‰...")
        
        # éªŒè¯å¿…éœ€åˆ—
        if recurrence_col not in df.columns:
            raise ValueError(f"ç¼ºå°‘å¤å‘æ ‡å¿—åˆ—: {recurrence_col}")
        
        # åˆ›å»ºæ—¶é—´çª—å£å†…å¤å‘æ ‡ç­¾
        if recurrence_time_col in df.columns:
            # åŸºäºå¤å‘æ—¶é—´åˆ›å»ºæ ‡ç­¾
            recurrence_in_window = (
                (df[recurrence_col] == 1) & 
                (df[recurrence_time_col] <= self.prediction_window)
            ).astype(int)
        else:
            # ç›´æ¥ä½¿ç”¨å¤å‘æ ‡å¿—
            recurrence_in_window = df[recurrence_col].astype(int)
        
        df = df.copy()
        df['recurrence_target'] = recurrence_in_window
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_patients = len(df)
        recurrence_cases = recurrence_in_window.sum()
        recurrence_rate = recurrence_cases / total_patients
        
        print(f"âœ… å¤å‘æ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"   æ€»æ‚£è€…æ•°: {total_patients}")
        print(f"   {self.prediction_window}æœˆå†…å¤å‘: {recurrence_cases} ({recurrence_rate:.2%})")
        
        return df
    
    def prepare_model(self):
        """å‡†å¤‡å¤å‘é¢„æµ‹æ¨¡å‹"""
        if self.model_type == 'xgboost':
            self.model = xgb.XGBClassifier(
                objective='binary:logistic',
                eval_metric='auc',
                random_state=42,
                n_estimators=200,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8
            )
        elif self.model_type == 'lightgbm':
            self.model = lgb.LGBMClassifier(
                objective='binary',
                metric='auc',
                random_state=42,
                n_estimators=200,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                verbose=-1
            )
        elif self.model_type == 'random_forest':
            self.model = RandomForestClassifier(
                n_estimators=200,
                max_depth=10,
                random_state=42,
                class_weight='balanced'  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
            )
        
        print(f"âœ… {self.model_type}å¤å‘é¢„æµ‹æ¨¡å‹å·²å‡†å¤‡")
        return self.model
    
    def train(self, df, target_col='recurrence_target', exclude_cols=None, test_size=0.2):
        """è®­ç»ƒå¤å‘é¢„æµ‹æ¨¡å‹"""
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒ{self.model_type}å¤å‘é¢„æµ‹æ¨¡å‹...")
        
        # å‡†å¤‡ç‰¹å¾
        exclude_cols = exclude_cols or [
            'patient_id', 'recurrence', 'recurrence_months', 'recurrence_target',
            'chief_complaint', 'imaging_result', 'survival_months', 'death_event'
        ]
        
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        
        X = df[feature_cols].copy()
        y = df[target_col].copy()
        
        # å¤„ç†åˆ†ç±»å˜é‡
        for col in X.columns:
            if X[col].dtype == 'object':
                X[col] = pd.Categorical(X[col]).codes
        
        # å¤„ç†ç¼ºå¤±å€¼
        X = X.fillna(X.median())
        
        self.feature_names = feature_cols
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        # è®­ç»ƒæ¨¡å‹
        if self.model is None:
            self.prepare_model()
        
        if self.model_type in ['xgboost', 'lightgbm']:
            self.model.fit(
                X_train, y_train,
                eval_set=[(X_test, y_test)],
                verbose=False
            )
        else:
            self.model.fit(X_train, y_train)
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_pred_proba = self.model.predict_proba(X_test)[:, 1]
        y_pred = self.model.predict(X_test)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        auc_score = roc_auc_score(y_test, y_pred_proba)
        
        # ä¿å­˜è®­ç»ƒç»“æœ
        self.training_results = {
            'model_type': self.model_type,
            'prediction_window': self.prediction_window,
            'train_size': len(X_train),
            'test_size': len(X_test),
            'auc_score': auc_score,
            'feature_count': X.shape[1],
            'recurrence_rate': y.mean(),
            'training_time': datetime.now().isoformat()
        }
        
        print(f"âœ… å¤å‘é¢„æµ‹æ¨¡å‹è®­ç»ƒå®Œæˆ")
        print(f"   è®­ç»ƒé›†å¤§å°: {len(X_train)}")
        print(f"   æµ‹è¯•é›†å¤§å°: {len(X_test)}")
        print(f"   AUCå¾—åˆ†: {auc_score:.4f}")
        print(f"   å¤å‘ç‡: {y.mean():.2%}")
        
        # ç”Ÿæˆè¯¦ç»†è¯„ä¼°
        self._generate_evaluation_report(y_test, y_pred, y_pred_proba)
        
        return {
            'model': self.model,
            'auc_score': auc_score,
            'y_test': y_test,
            'y_pred': y_pred,
            'y_pred_proba': y_pred_proba
        }
    
    def _generate_evaluation_report(self, y_true, y_pred, y_pred_proba):
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“Š å¤å‘é¢„æµ‹æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
        
        # åˆ†ç±»æŠ¥å‘Š
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_true, y_pred, target_names=['æ— å¤å‘', 'å¤å‘']))
        
        # ROCæ›²çº¿
        from sklearn.metrics import roc_curve, precision_recall_curve
        
        fpr, tpr, _ = roc_curve(y_true, y_pred_proba)
        precision, recall, _ = precision_recall_curve(y_true, y_pred_proba)
        
        plt.figure(figsize=(15, 5))
        
        # ROCæ›²çº¿
        plt.subplot(1, 3, 1)
        plt.plot(fpr, tpr, label=f'ROCæ›²çº¿ (AUC = {roc_auc_score(y_true, y_pred_proba):.3f})')
        plt.plot([0, 1], [0, 1], 'k--', label='éšæœºåˆ†ç±»å™¨')
        plt.xlabel('å‡é˜³æ€§ç‡')
        plt.ylabel('çœŸé˜³æ€§ç‡')
        plt.title('ROCæ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # PRæ›²çº¿
        plt.subplot(1, 3, 2)
        from sklearn.metrics import average_precision_score
        ap_score = average_precision_score(y_true, y_pred_proba)
        plt.plot(recall, precision, label=f'PRæ›²çº¿ (AP = {ap_score:.3f})')
        plt.xlabel('å¬å›ç‡')
        plt.ylabel('ç²¾ç¡®ç‡')
        plt.title('Precision-Recallæ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
        plt.subplot(1, 3, 3)
        plt.hist(y_pred_proba[y_true == 0], bins=20, alpha=0.7, label='æ— å¤å‘', density=True)
        plt.hist(y_pred_proba[y_true == 1], bins=20, alpha=0.7, label='å¤å‘', density=True)
        plt.xlabel('é¢„æµ‹æ¦‚ç‡')
        plt.ylabel('å¯†åº¦')
        plt.title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ')
        plt.legend()
        
        plt.tight_layout()
        plt.show()
    
    def predict_recurrence(self, X):
        """é¢„æµ‹å¤å‘é£é™©"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        # ç¡®ä¿ç‰¹å¾é¡ºåºä¸€è‡´
        if hasattr(X, 'columns') and self.feature_names:
            X = X[self.feature_names]
        
        # å¤„ç†åˆ†ç±»å˜é‡
        X_processed = X.copy()
        for col in X_processed.columns:
            if X_processed[col].dtype == 'object':
                X_processed[col] = pd.Categorical(X_processed[col]).codes
        
        # å¤„ç†ç¼ºå¤±å€¼
        X_processed = X_processed.fillna(X_processed.median())
        
        # é¢„æµ‹
        probabilities = self.model.predict_proba(X_processed)[:, 1]
        predictions = self.model.predict(X_processed)
        
        # é£é™©åˆ†å±‚
        risk_levels = []
        for prob in probabilities:
            if prob > 0.7:
                risk_levels.append('é«˜å±')
            elif prob > 0.5:
                risk_levels.append('ä¸­é«˜å±')
            elif prob > 0.3:
                risk_levels.append('ä¸­ç­‰')
            else:
                risk_levels.append('ä½å±')
        
        return {
            'predictions': predictions,
            'probabilities': probabilities,
            'risk_levels': risk_levels,
            'prediction_window': self.prediction_window
        }
    
    def get_feature_importance(self, top_n=10):
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        if hasattr(self.model, 'feature_importances_'):
            importances = self.model.feature_importances_
        else:
            print("âš ï¸  è¯¥æ¨¡å‹ä¸æ”¯æŒç‰¹å¾é‡è¦æ€§åˆ†æ")
            return None
        
        if self.feature_names:
            feature_importance = pd.DataFrame({
                'feature': self.feature_names,
                'importance': importances
            }).sort_values('importance', ascending=False)
        else:
            feature_importance = pd.DataFrame({
                'feature': [f'feature_{i}' for i in range(len(importances))],
                'importance': importances
            }).sort_values('importance', ascending=False)
        
        # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
        plt.figure(figsize=(12, 6))
        top_features = feature_importance.head(top_n)
        
        plt.barh(range(len(top_features)), top_features['importance'])
        plt.yticks(range(len(top_features)), top_features['feature'])
        plt.xlabel('é‡è¦æ€§å¾—åˆ†')
        plt.title(f'å¤å‘é¢„æµ‹æ¨¡å‹ - Top {top_n} ç‰¹å¾é‡è¦æ€§')
        plt.gca().invert_yaxis()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
        
        return feature_importance
    
    def analyze_recurrence_patterns(self, df, recurrence_col='recurrence', 
                                  recurrence_time_col='recurrence_months'):
        """åˆ†æå¤å‘æ¨¡å¼"""
        print("ğŸ” åˆ†æå¤å‘æ¨¡å¼...")
        
        if recurrence_col not in df.columns:
            print(f"âš ï¸  ç¼ºå°‘å¤å‘åˆ—: {recurrence_col}")
            return None
        
        recurrence_data = df[df[recurrence_col] == 1].copy()
        
        if len(recurrence_data) == 0:
            print("âš ï¸  æ•°æ®ä¸­æ— å¤å‘ç—…ä¾‹")
            return None
        
        analysis_results = {
            'total_recurrences': len(recurrence_data),
            'recurrence_rate': len(recurrence_data) / len(df)
        }
        
        if recurrence_time_col in df.columns:
            recurrence_times = recurrence_data[recurrence_time_col].dropna()
            
            analysis_results.update({
                'median_recurrence_time': recurrence_times.median(),
                'mean_recurrence_time': recurrence_times.mean(),
                'early_recurrence_rate': (recurrence_times <= 12).mean(),  # 1å¹´å†…å¤å‘ç‡
                'late_recurrence_rate': (recurrence_times > 24).mean()      # 2å¹´åå¤å‘ç‡
            })
            
            # ç»˜åˆ¶å¤å‘æ—¶é—´åˆ†å¸ƒ
            plt.figure(figsize=(12, 4))
            
            plt.subplot(1, 2, 1)
            recurrence_times.hist(bins=20, alpha=0.7, edgecolor='black')
            plt.axvline(recurrence_times.median(), color='red', linestyle='--', 
                       label=f'ä¸­ä½æ•°: {recurrence_times.median():.1f}æœˆ')
            plt.xlabel('å¤å‘æ—¶é—´ (æœˆ)')
            plt.ylabel('æ‚£è€…æ•°')
            plt.title('å¤å‘æ—¶é—´åˆ†å¸ƒ')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # ç´¯ç§¯å¤å‘ç‡
            plt.subplot(1, 2, 2)
            time_points = np.arange(0, recurrence_times.max() + 1, 3)
            cumulative_recurrence = []
            
            for t in time_points:
                cum_rate = (recurrence_times <= t).mean()
                cumulative_recurrence.append(cum_rate)
            
            plt.plot(time_points, cumulative_recurrence, marker='o')
            plt.xlabel('æ—¶é—´ (æœˆ)')
            plt.ylabel('ç´¯ç§¯å¤å‘ç‡')
            plt.title('ç´¯ç§¯å¤å‘ç‡æ›²çº¿')
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.show()
        
        print(f"ğŸ“Š å¤å‘æ¨¡å¼åˆ†æç»“æœ:")
        for key, value in analysis_results.items():
            if isinstance(value, float):
                print(f"   {key}: {value:.3f}")
            else:
                print(f"   {key}: {value}")
        
        return analysis_results
    
    def identify_risk_factors(self, df, recurrence_col='recurrence'):
        """è¯†åˆ«å¤å‘é£é™©å› ç´ """
        print("ğŸ” è¯†åˆ«å¤å‘é£é™©å› ç´ ...")
        
        risk_factors = {}
        
        # æ•°å€¼å˜é‡çš„é£é™©å› ç´ åˆ†æ
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols:
            if col != recurrence_col:
                recurrence_group = df[df[recurrence_col] == 1][col].dropna()
                non_recurrence_group = df[df[recurrence_col] == 0][col].dropna()
                
                if len(recurrence_group) > 0 and len(non_recurrence_group) > 0:
                    # tæ£€éªŒ
                    from scipy.stats import ttest_ind
                    t_stat, p_value = ttest_ind(recurrence_group, non_recurrence_group)
                    
                    risk_factors[col] = {
                        'recurrence_mean': recurrence_group.mean(),
                        'non_recurrence_mean': non_recurrence_group.mean(),
                        'p_value': p_value,
                        'significant': p_value < 0.05,
                        'effect_direction': 'increase' if recurrence_group.mean() > non_recurrence_group.mean() else 'decrease'
                    }
        
        # åˆ†ç±»å˜é‡çš„é£é™©å› ç´ åˆ†æ
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns
        for col in categorical_cols:
            if col != recurrence_col:
                # å¡æ–¹æ£€éªŒ
                from scipy.stats import chi2_contingency
                contingency_table = pd.crosstab(df[col], df[recurrence_col])
                
                if contingency_table.shape[0] > 1 and contingency_table.shape[1] > 1:
                    chi2, p_value, dof, expected = chi2_contingency(contingency_table)
                    
                    risk_factors[col] = {
                        'contingency_table': contingency_table.to_dict(),
                        'chi2_statistic': chi2,
                        'p_value': p_value,
                        'significant': p_value < 0.05
                    }
        
        # ç­›é€‰æ˜¾è‘—çš„é£é™©å› ç´ 
        significant_factors = {k: v for k, v in risk_factors.items() if v.get('significant', False)}
        
        print(f"âœ… å‘ç°{len(significant_factors)}ä¸ªæ˜¾è‘—é£é™©å› ç´ :")
        for factor, stats in significant_factors.items():
            print(f"   {factor}: p={stats['p_value']:.4f}")
        
        return risk_factors
    
    def predict(self, X):
        """é¢„æµ‹æ–°æ ·æœ¬å¤å‘é£é™©"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        # æ•°æ®é¢„å¤„ç†
        X_processed = X.copy()
        
        # ç¡®ä¿ç‰¹å¾é¡ºåº
        if hasattr(X, 'columns') and self.feature_names:
            X_processed = X_processed[self.feature_names]
        
        # å¤„ç†åˆ†ç±»å˜é‡
        for col in X_processed.columns:
            if X_processed[col].dtype == 'object':
                X_processed[col] = pd.Categorical(X_processed[col]).codes
        
        # å¤„ç†ç¼ºå¤±å€¼
        X_processed = X_processed.fillna(X_processed.median())
        
        # é¢„æµ‹
        probabilities = self.model.predict_proba(X_processed)[:, 1]
        predictions = self.model.predict(X_processed)
        
        return predictions, probabilities
    
    def save_model(self, file_path):
        """ä¿å­˜æ¨¡å‹"""
        import joblib
        
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        model_data = {
            'model': self.model,
            'model_type': self.model_type,
            'prediction_window': self.prediction_window,
            'feature_names': self.feature_names,
            'training_results': self.training_results
        }
        
        joblib.dump(model_data, file_path)
        print(f"âœ… å¤å‘é¢„æµ‹æ¨¡å‹å·²ä¿å­˜: {file_path}")
    
    def load_model(self, file_path):
        """åŠ è½½æ¨¡å‹"""
        import joblib
        
        model_data = joblib.load(file_path)
        
        self.model = model_data['model']
        self.model_type = model_data['model_type']
        self.prediction_window = model_data['prediction_window']
        self.feature_names = model_data['feature_names']
        self.training_results = model_data.get('training_results', {})
        
        print(f"âœ… å¤å‘é¢„æµ‹æ¨¡å‹å·²åŠ è½½: {file_path}")
        print(f"   æ¨¡å‹ç±»å‹: {self.model_type}")
        print(f"   é¢„æµ‹çª—å£: {self.prediction_window}æœˆ")
        
        return self.model


def create_recurrence_pipeline(data_path, recurrence_col='recurrence', 
                             recurrence_time_col='recurrence_months',
                             prediction_window=24, model_type='xgboost'):
    """åˆ›å»ºå®Œæ•´çš„å¤å‘é¢„æµ‹æµæ°´çº¿"""
    print("ğŸ”¬ å¯åŠ¨å¤å‘é¢„æµ‹æµæ°´çº¿...")
    
    # 1. åŠ è½½æ•°æ®
    from .data_engineering import DataProcessor
    processor = DataProcessor()
    
    df = processor.load_data(data_path)
    if df is None:
        return None
    
    # 2. æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹
    df_clean = processor.clean_data(df)
    df_features = processor.feature_engineering(df_clean)
    
    # 3. å¤å‘é¢„æµ‹åˆ†æ
    predictor = RecurrencePredictor(model_type, prediction_window)
    
    # å‡†å¤‡å¤å‘æ•°æ®
    df_recurrence = predictor.prepare_recurrence_data(
        df_features, recurrence_col, recurrence_time_col
    )
    
    # åˆ†æå¤å‘æ¨¡å¼
    recurrence_patterns = predictor.analyze_recurrence_patterns(
        df_recurrence, recurrence_col, recurrence_time_col
    )
    
    # è¯†åˆ«é£é™©å› ç´ 
    risk_factors = predictor.identify_risk_factors(df_recurrence, recurrence_col)
    
    # è®­ç»ƒæ¨¡å‹
    training_results = predictor.train(df_recurrence)
    
    # ç‰¹å¾é‡è¦æ€§åˆ†æ
    feature_importance = predictor.get_feature_importance()
    
    # ä¿å­˜æ¨¡å‹
    model_path = f"models/recurrence_{model_type}_{prediction_window}m_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
    predictor.save_model(model_path)
    
    return {
        'predictor': predictor,
        'training_results': training_results,
        'recurrence_patterns': recurrence_patterns,
        'risk_factors': risk_factors,
        'feature_importance': feature_importance,
        'model_path': model_path
    }
